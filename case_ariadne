# -*- coding: utf-8 -*-
"""
Created on Mon Mar  6 01:25:01 2023

@author: F0126988


"""
import pandas as pd
import seaborn as sns 
import matplotlib.pyplot as plt 
import numpy as np
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import StandardScaler
from sklearn.decomposition import PCA
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn import metrics
import optuna
from sklearn.model_selection import cross_val_score
from sklearn.model_selection import train_test_split

#Definição da função objetivo para tunar os parametros do modelo de regressão logística
def lr_objective(trial):
    
    # Definição do espaço de busca dos hiper parametros do modelo de regressão logístia
    penalty = trial.suggest_categorical('penalty', ['l2','l1'])
    C = trial.suggest_loguniform('C', 0.001, 100)
    
    # Definição do espaço de busca dos hiperparametros para busca  do número de compoenentes da PCA
    n_components = trial.suggest_int('n_components', 1, X.shape[1])
    
    # Criação da pipeline de treinamento. A etapa de PCA é utilizada porque tem o potencial de mitigar
    #os possíveis problemas causados por multicolinearidade entre as variáveis do modelo
    
    lr_pipeline = Pipeline([
        ('scaler', StandardScaler()),
        ('pca', PCA(n_components=n_components)),
        ('logreg', LogisticRegression(penalty=penalty, C=C,solver='liblinear'))
    ])
    
   

    #valiação do score do modelo em 5 camadas distintas do conjunto de treinamento utilizado o score ROC_AUC
    score = cross_val_score(lr_pipeline, X_train, y_train, cv=5,scoring='roc_auc', n_jobs=-1).mean()
    

    return score

#Definição da função objetivo para tunar os parametros do modelo Random Forest
def rf_objective(trial):
    # do espaço de busca dos hiper parametros do modelo Random Forest
    n_estimators = trial.suggest_int('n_estimators', 100, 1000, step=100)
    max_depth = trial.suggest_int('max_depth', 3, 10)
    min_samples_split = trial.suggest_int('min_samples_split', 2, 10)
    min_samples_leaf = trial.suggest_int('min_samples_leaf', 1, 10)

    # Definição do modelo de classificação Random Forest de acordo com os hiper parametros sugeridos
    rf = RandomForestClassifier(n_estimators=n_estimators, max_depth=max_depth, 
                                min_samples_split=min_samples_split, min_samples_leaf=min_samples_leaf, 
                                random_state=42)

  
    #valiação do score do modelo em 5 camadas distintas do conjunto de treinamento utilizado o score ROC_AUC
    score = cross_val_score(rf, X_train, y_train, cv=5, scoring='roc_auc', n_jobs=-1).mean()
   
    return score

#Função para geração da tabela de KS. Não interfere no desenvolvimento do modelo
def get_ks_table(y_true, y_pred,faixas):


    data = pd.DataFrame()

    data['target'] = y_true
    data['target0'] = 1 - y_true
    
    data['prob'] = y_pred
 
    data['bucket'] = pd.qcut(data['prob'], faixas, duplicates='drop')

    grouped = data.groupby('bucket', as_index=False)

    kstable = pd.DataFrame()
   
    kstable['min_prob'] = grouped.min()['prob']
    kstable['max_prob'] = grouped.max()['prob']

    kstable['events'] = grouped.sum()['target']
    kstable['nonevents'] = grouped.sum()['target0']
    
    kstable = kstable.sort_values(
        by="min_prob", ascending=True).reset_index(drop=True)

    kstable['event_rate'] = (
        kstable.events / data['target'].sum()).apply('{0:.2%}'.format)
    kstable['nonevent_rate'] = (
        kstable.nonevents / data['target0'].sum()).apply('{0:.2%}'.format)

    kstable['cum_eventrate'] = (kstable.events / data['target'].sum()).cumsum()
    kstable['cum_noneventrate'] = (
        kstable.nonevents / data['target0'].sum()).cumsum()

    kstable['Percentil'] = (kstable.events.cumsum() +
                            kstable.nonevents.cumsum())/len(y_pred)

    kstable['KS'] = np.round(kstable['cum_noneventrate']-kstable['cum_eventrate'], 3) 
    # Formatação
    kstable['cum_eventrate'] = kstable['cum_eventrate'].apply('{0:.2%}'.format)
    kstable['cum_noneventrate'] = kstable['cum_noneventrate'].apply(
        '{0:.2%}'.format)
    
  
    kstable['Nímero de Registros']=kstable['events'] + kstable['nonevents']

    #total_propostas = kstable['Nímero de Registros'].sum()
    kstable['Nímero de Registros Acumulado'] = kstable['Nímero de Registros'].cumsum()
    kstable['Eventos Acumulados'] =kstable['events'].cumsum()     
    kstable['Taxa de Eventos Acumulada'] = (kstable['Eventos Acumulados']/ kstable['Nímero de Registros Acumulado'])
    kstable['Taxa de Eventos Acumulada']=kstable['Taxa de Eventos Acumulada'].apply('{0:.2%}'.format)
    
  
    # # Display KS
    from colorama import Fore
    print(Fore.WHITE + "KS is " + str(max(kstable['KS'])*100)+"%"+ " at decile " + str((kstable.index[kstable['KS']==max(kstable['KS'])][0])))
    
    

    return(kstable)

def bar_plot_perc(x_axis,grupo,y_label,titulo,df):
    # plot
    ax = sns.countplot(x=x_axis, hue=grupo, data=df)
    ax.set(ylabel=y_label, title=titulo)

    # Adiciona Anotações
    for c in ax.containers:
        
        # custom label calculates percent and add an empty string so 0 value bars don't have a number
        
        labels = [f'{h/df.eval(x_axis).count()*100:0.1f}%' if (h := v.get_height()) > 0 else '' for v in c]
        
        ax.bar_label(c, labels=labels, label_type='edge')

    plt.show()

def eda_plots(df):
    #Distribuição da variável target
    bar_plot_perc("target","target","Quantidade","Quantidade e Percentual do Total",df)

    #Distribuição da variável v1 e variável target

    bar_plot_perc("v1","target","Quantidade","Quantidade e Percentual do Total",df)

    #Distribuição da variável v3 e variável target

    bar_plot_perc("v3","target","Quantidade","Quantidade e Percentual do Total",df)


    # sns.pairplot(df, hue = "target", 
    #             diag_kind='kde', kind='scatter', palette='husl')
    # plt.show()

    #Matriz de correlação e heatmap
    correlacao = df.corr()
    plt.figure(figsize=(16,5))
    ax = sns.heatmap(correlacao,cmap='GnBu',annot=True)

    #Plot box plot e distribuição por classe da variável target
    plt.figure(figsize=(16, 25))
    for i, col in enumerate(df.columns):
        if(col!='target'):
            plt.subplot(8, 4, i*2+1)
            plt.subplots_adjust(hspace =.5, wspace=.3)
            
            plt.grid(True)
            plt.title(col)
            sns.kdeplot(df.loc[df["target"]==0, col], label="Sem Evento", color = "green", shade=True, kernel='gau', cut=0)
            sns.kdeplot(df.loc[df["target"]==1, col], label="Evento",  color = "red", shade=True, kernel='gau', cut=0)
            plt.subplot(8, 4, i*2+2) 
            sns.boxplot(y = col, data = df, x="target", palette = ["green", "red"])
            
        
    #Taxa de eventos de acordo com as classes das variáveis categóricas
    x = pd.crosstab(df["v1"], df['target'])
    x.apply(lambda z: z/z.sum(), axis=1)    

    x = pd.crosstab(df["v3"], df['target'])
    x.apply(lambda z: z/z.sum(), axis=1)
    x.style.background_gradient(cmap='summer_r')


    #Distribuição das variaveis



    # f,ax=plt.subplots(2,4,figsize=(20,8))
    # plt.subplots_adjust(wspace=.3)
    # ax = ax.flatten()
    # for i, col in enumerate(df.columns):
    #     if(col!='target'):
    #         sns.distplot(df[col],ax=ax[i])

    # plt.show()
       
        
#Leitura da base de dados
df = pd.read_csv(r'D:\git\sicoob\data\DADOS_CASE_MODELAGEM_SR.csv',sep=';')


#descrição estatísitica básica de cada coluna

descricao = df.describe(include='all')


#Verifica a quantidade de valores nulos em cada coluna
quantidade_nulos = df.isnull().sum()
quantidade_exemplos = len(df)
percentual_nulos = round(quantidade_nulos*100/quantidade_exemplos,2)

#Criação de um dataframe sumarizando a quantidade e percentual de nulos de cada variável
df_missing = pd.DataFrame({'QTD': quantidade_nulos,'percentual':percentual_nulos})
#Não foram dectados valores nulos em nenhuma coluna

#Número de valores únicos em cada coluna
valores_unicos = df.nunique()

#Análise exploratória dos dados
eda_plots(df)

#Separação da variável target e features do modelo
y = df[['target']]
X = df.drop('target',axis=1)


#Separação dos conjuntos de treinamento e teste
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.20, random_state=1, stratify=y)

#Configuração do estudo para obtenção dos melhores hiper parametros para o modelo
#de regressão logística
lr_study = optuna.create_study(direction='maximize')
lr_study.optimize(lr_objective, n_trials=100)   


print("Logistic Regression Best Score: {:.3f}".format(lr_study.best_value))
print("Logistic Regression Best Parameters: ", lr_study.best_params)

#Configuração do estudo para obtenção dos melhores hiper parametros para o Random Forest

rf_study = optuna.create_study(direction='maximize')
rf_study.optimize(rf_objective, n_trials=100)

print("Random Forest Best Score: {:.3f}".format(rf_study.best_value))
print("Random Forest Best rameters: ", rf_study.best_params)

#Uma vez que o modelo de regressão logística foi aquele que apresentou melhor ROC AUC, os
#parametros do melhor modelo serão utilizados para treinamento do modelo final
pipe = Pipeline([
    ('scaler', StandardScaler()),
    ('pca', PCA(n_components=lr_study.best_params['n_components'])),
    ('logreg', LogisticRegression(penalty=lr_study.best_params['penalty'], C=lr_study.best_params['C'],solver='liblinear'))
])
pipe.fit(X_train, y_train)

#Obtenção do score para cada uma das 10 partes do dataset de treinamento. É uma etapa útil para verficar se
#existem segmentos do conjunto de treinamento para os quais há variação significativa da performance do modelo
scores_lr = cross_val_score(pipe, X_train, y_train, cv=10, scoring='roc_auc', n_jobs=-1)

     
#Extraçãp de variáveis da pipeline que serão utilizadas para a análise do resultado final        
logreg_model = pipe.named_steps['logreg'] #Extração do modelo de regressão logística
pca = pipe.named_steps['pca'] #Extração da transformação PCA

#Obtenção dos coeficientes do modelo
intercept_transformed = logreg_model.intercept_
coef_transformed  = logreg_model.coef_


#Realização da transformação inversa  da PCA sobre os coeficientes do modelo para inferir a importância
#das variáveis originais do dataset de treinamento
coef_original = pca.inverse_transform(coef_transformed)
feature_importance = abs(coef_original[0])

#Criação de um gráfico de barras mostrando a importância das variáveis do modelo
df_feature_importance = pd.DataFrame({'Importância':feature_importance,'Variável': X_train.columns}).sort_values(by='Importância',ascending=False)

p = sns.barplot(x="Variável", y="Importância", data=df_feature_importance, ci=None,color=sns.xkcd_rgb['dark mint'])

for bars in p.containers:
        p.bar_label(bars, fmt='%.2f')


# Classificação do dataset de treinamento utilizando a pipeline do melhor modelo
y_pred = pipe.predict(X_test)

#Cálculo da curva ROC_AUC da classiicação do conjunto de treinamento
plt.clf()
y_pred_proba = pipe.predict_proba(X_test)[::,1]
fpr, tpr, _ = metrics.roc_curve(y_test,  y_pred_proba)
auc = metrics.roc_auc_score(y_test, y_pred_proba)
plt.plot(fpr,tpr,label="Dataset de Teste, auc={:.3f}".format(auc))
plt.legend(loc=4)
plt.show()

#Obtenção da tabela para análise da distribuição de eventos por faixa de score
kstable = get_ks_table(y_test, y_pred_proba,8)

